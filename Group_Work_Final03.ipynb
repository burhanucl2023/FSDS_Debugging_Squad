{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "bibliography: bib1.bib\n",
        "csl: harvard-cite-them-right.csl\n",
        "title: Group Debugging Squad\n",
        "execute:\n",
        "  echo: false\n",
        "format:\n",
        "  html:\n",
        "    theme:\n",
        "      - minty\n",
        "      - css/web.scss\n",
        "    code-copy: true\n",
        "    code-link: true\n",
        "    toc: true\n",
        "    toc-title: On this page\n",
        "    toc-depth: 2\n",
        "    toc_float:\n",
        "      collapsed: false\n",
        "      smooth_scroll: true\n",
        "  pdf:\n",
        "    include-in-header:\n",
        "      text: |\n",
        "        \\addtokomafont{disposition}{\\rmfamily}\n",
        "    mainfont: Spectral\n",
        "    sansfont: Roboto\n",
        "    monofont: JetBrainsMono-Regular\n",
        "    papersize: a4\n",
        "    geometry:\n",
        "      - top=25mm\n",
        "      - left=40mm\n",
        "      - right=30mm\n",
        "      - bottom=25mm\n",
        "      - heightrounded\n",
        "    toc: false\n",
        "    number-sections: false\n",
        "    colorlinks: true\n",
        "    highlight-style: github\n",
        "---"
      ],
      "id": "a71aec58"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Group Debugging Squad_Submission\n",
        "format: pdf\n",
        "execute:\n",
        "  echo: false\n",
        "---"
      ],
      "id": "42725c20"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Declaration of Authorship {.unnumbered .unlisted}\n",
        "\n",
        "We, [The Debugging Squad], confirm that the work presented in this assessment is our own. Where information has been derived from other sources, we confirm that this has been indicated in the work. Where a Large Language Model such as ChatGPT has been used we confirm that we have made its contribution to the final submission clear.\n",
        "\n",
        "Date: 21.December 2023 \n",
        "\n",
        "Student Numbers: \n",
        "1. Viktoria Pues (23116898)\n",
        "2. Yicong Li (23219797)\n",
        "3. Victoria chen (23233478)\n",
        "\n",
        "## Brief Group Reflection\n",
        "\n",
        "| What Went Well | What Was Challenging |\n",
        "| -------------- | -------------------- |\n",
        "| Working with the coding environment despite limited experience             | Conceptualising question 7                     |\n",
        "|   Splitting the work         | Time management in small group                 |\n",
        "\n",
        "## Priorities for Feedback\n",
        "\n",
        "Are there any areas on which you would appreciate more detailed feedback if we're able to offer it?\n",
        "\n",
        "- Structuring the cleaning of data\n",
        "- Extend of policy recommendations (enough detail)\n",
        "- Enough detail on the model and limitations. would this model work in a real life consultancy project?\n",
        "\n",
        "\n",
        "```{=html}\n",
        "<style type=\"text/css\">\n",
        ".duedate {\n",
        "  border: dotted 2px red; \n",
        "  background-color: rgb(255, 235, 235);\n",
        "  height: 50px;\n",
        "  line-height: 50px;\n",
        "  margin-left: 40px;\n",
        "  margin-right: 40px\n",
        "  margin-top: 10px;\n",
        "  margin-bottom: 10px;\n",
        "  color: rgb(150,100,100);\n",
        "  text-align: center;\n",
        "}\n",
        "</style>\n",
        "```\n",
        "\n",
        "{{< pagebreak >}}\n",
        "\n",
        "\n",
        "\n",
        "# Response to Questions\n",
        "\n",
        "## 1. Who collected the data?\n",
        "\n",
        "The data on the Inside Airbnb website was collected by the Inside Airbnb Project team, which is led by Murray Cox, an artist, activist and technologist [@insideairbnb]. \n",
        "\n",
        "## 2. Why did they collect it?\n",
        "\n",
        "Airbnb is a company providing a peer to peer platform for short-term rental (STR) accommodations in cities around the world with over 4 million active hosts [@airbnb]. \n",
        "\n",
        "As outlined in its data policies, Inside Airbnb has two objectives :  \n",
        "\n",
        "1.\tMake data on Airbnb listings available for analysis and to quantify the impact of STR on local communities.\n",
        "    \n",
        "3.\tProvide a platform for community members, researchers, activists and policy makers to advocate for policies that mitigate Airbnb's negative impacts on local communities. [@insideairbnb]\n",
        "\n",
        "## 3. How was the data collected?  \n",
        "\n",
        "Inside Airbnb's data was collected through webscraping. Data on individual listings is extracted from the Airbnb website for different cities. Inside Airbnb has collected data for 92 cities in Europe and North America and 21 cities in Asia and the Pacific, Africa, South America. For each listing, a range of data points is collected including on the host, location, property/room type, price, stay, and reviews. The collected data is verified, cleaned, analysed and aggregated by the project team and stored in seperate csv files for each city, which are available to download.  To remain uptodate, the process of webscraping is usually repeated four times a year. So, there a four data sets per city per year. [@insideairbnb] \n",
        "\n",
        "## 4. How does the method of collection impact the completeness and/or accuracy of its representation of the process it seeks to study, and what wider issues does this raise?\n",
        "\n",
        "The datasets show a snapshot of listings available at a particular time. The Airbnb website is changing continuously as users add, delete or change listings. As illustrated by @Murray2016, the website can dramatically change from one day to the next. In 2015, Airbnb published data on their operation in New York using a snapshot of November 17, 2015. The data was misleading as they did not show that a  targeted purge of more than 1,000 listings was implemented just before that date. In order to accurately study the impact of Airbnb on local communities, comparing data over time would be beneficial. \n",
        "\n",
        "## 5. What ethical considerations does the use of this data raise? \n",
        "\n",
        "There are a number of ethical concerns to consider when using the data: \n",
        "\n",
        "-\tAirbnb prohibits  data scraping in its terms and conditions (T&Cs). However, for T&Cs to be binding, they require an agreement from both parties. Logging into the website is considered as agreement. However, as web scraping is an automated process without logging in, it is considered legal in this case.  [@airbtics] \n",
        "\n",
        "-\tThe data includes personal information, e.g.,  images and names of hosts and their homes. Hosts did not give consent for their data to be included in the Inside Airbnb Project, however one could argue, that by making their data public on Airbnb, they gave up data protection rights on this information.\n",
        "  \n",
        "-\tGeocoded data is especially sensitive information.[@Bemt:2018] Disclosing the location of homes, could pose a safety risk to hosts. Airbnb mitigates this risk by anonymizing listings on the map. The location is within 150 metres of the actual address. \n",
        "  \n",
        "-\tPost-colonial scholars argue that we need to better understand spatial processes in cities of the global south, including those related to digital technologies, such as Airbnb.[@Elwood:2018] Cities in the Global South are underrepresented on Inside Airbnb (see above) and correstonding analysis may have a Global North bias. \n",
        "\n",
        "## 6. With reference to the data (*i.e.* using numbers, figures, maps, and descriptive statistics), what does an analysis of Hosts and Listing types suggest about the nature of Airbnb lets in London? \n",
        "\n",
        "To describe the nature of Airbnb lets in London, we analysed hosts and listing types, looking more closely at occupancy rate of listings following a preliminary data cleaning process including selection of relevant columns, filtering of probelmatic rows, and fixing of column types.\n"
      ],
      "id": "6a4f18d2"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# First of all_Data cleaning"
      ],
      "id": "f94127d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# load all the libraries needed \n",
        "import os\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "import gzip\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.simplefilter(action='ignore', category=pd.errors.DtypeWarning)\n",
        "\n",
        "def cache_data(src: str, dest: str) -> str:\n",
        "    \"\"\"\n",
        "       \n",
        "    Downloads and caches a remote file locally.\n",
        "    \n",
        "    The function sits between the 'read' step of a pandas or geopandas\n",
        "    data frame and downloading the file from a remote location. The idea\n",
        "    is that it will save it locally so that you don't need to remember to\n",
        "    do so yourself. Subsequent re-reads of the file will return instantly\n",
        "    rather than downloading the entire file for a second or n-th itme.\n",
        "\n",
        "    We've built in some basic logic around looking at the extension of the \n",
        "    destination file and converting it accordingly *once* it is downloaded.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    src : str\n",
        "        The remote *source* for the file, any valid URL should work.\n",
        "    dest : str\n",
        "        The *destination* location to save the downloaded file.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        A string representing the local location of the file.\n",
        "\n",
        "        \n",
        "    \"\"\"\n",
        "    \n",
        "    url = urlparse(src)\n",
        "    fn = os.path.split(url.path)[-1]\n",
        "    dfn = os.path.join(dest, fn)\n",
        "\n",
        "    if not os.path.isfile(dfn):\n",
        "        #print(f\"{dfn} not found, downloading!\")\n",
        "\n",
        "        path = os.path.split(dest)\n",
        "\n",
        "        if len(path) >= 1 and path[0] != '':\n",
        "            os.makedirs(os.path.join(*path), exist_ok=True)\n",
        "\n",
        "        with open(dfn, \"wb\") as file:\n",
        "            response = requests.get(src, stream=True)\n",
        "            shutil.copyfileobj(response.raw, file)\n",
        "\n",
        "        #print(\"\\tDone downloading...\")\n",
        "\n",
        "    #else:\n",
        "        #print(f\"Found {dfn} locally!\")\n",
        "\n",
        "    return dfn\n",
        "\n",
        "# Define the destination directory and source path\n",
        "ddir = os.path.join('data', 'listings')  # destination directory\n",
        "spath = 'http://data.insideairbnb.com/united-kingdom/england/london/2023-09-06/data/listings.csv.gz'  # source path\n",
        "\n",
        "# Use the cache_data function to download and cache the file\n",
        "cached_file_path = cache_data(spath, ddir)\n",
        "\n",
        "# Read the cached file into a pandas DataFrame\n",
        "listings_df = pd.read_csv(cached_file_path)\n",
        "\n",
        "# Now 'listings_df' contains the DataFrame with the data from the cached CSV file\n",
        "#print('Done.')"
      ],
      "id": "8131cdb5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Loading borough map\n",
        "\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the London borough boundary shapefile\n",
        "# gdf = gpd.read_file(\"C:/Users/avb19/Documents/CASA/FSDS/FSDS_Debugging_Squad/ESRI/London_Borough_Excluding_MHW.shp\")\n",
        "\n",
        "ddir  = os.path.join('data','geo') # destination directory\n",
        "spath = 'https://github.com/jreades/fsds/blob/master/data/src/' # source path\n",
        "\n",
        "gdf = gpd.read_file( cache_data(spath+'Boroughs.gpkg?raw=true', ddir) )\n",
        "\n",
        "#print(gdf.crs)\n",
        "#print(gdf.head())\n",
        "#print(gdf.columns)\n",
        "#gdf.plot()"
      ],
      "id": "11cefb61",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Data Cleaning"
      ],
      "id": "f319a0c0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# View columns\n",
        "#print(listings_df.columns.to_list())"
      ],
      "id": "84a2df7b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Select the columns on host and listing type from list above that are of interested in for this question. \n",
        "cols = ['id', 'listing_url', 'name', 'description', \n",
        "        'host_id', 'host_name', 'host_since', 'host_location',\n",
        "        'host_neighbourhood','host_listings_count', 'host_total_listings_count', 'host_identity_verified',\n",
        "        'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed',\n",
        "        'latitude', 'longitude',\n",
        "        'property_type', 'room_type', 'accommodates', 'bedrooms', 'beds',\n",
        "        'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', \n",
        "        'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'reviews_per_month',\n",
        "        'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms']\n",
        "\n",
        "#print(df_2023_Season4_SC.head()) # Just check\n",
        "#cols.index('calculated_host_listings_count_shared_rooms') # Prints: 34"
      ],
      "id": "c46f2c8c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Delete the df and read in again, only using the selected columns \n",
        "# del(listings_df)\n",
        "listings_df1 = pd.read_csv(cached_file_path)[cols]\n",
        "#print(f\"Data frame is {listings_df1.shape[0]:,} x {listings_df1.shape[1]}\")\n",
        "#print(listings_df1.columns.to_list())"
      ],
      "id": "d53f6ffc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Identify problematic rows \n",
        "#listings_df1.isnull().sum(axis=0).sort_values(ascending=False)"
      ],
      "id": "8106fd1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# There are some columns with very high numbers of na. They dont seem relevant for the analysis, so we drop them. \n",
        "columns_drop = ['neighbourhood_group_cleansed', 'neighbourhood', 'host_neighbourhood', 'host_location'] \n",
        "listings_df1.drop(columns=columns_drop, inplace=True)"
      ],
      "id": "8d2baa0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# There are a few columns that have exactly 5 na. Looks like these are not complete listings. So we drop them. \n",
        "cols_na = ['host_name', 'host_since', 'host_listings_count', 'host_total_listings_count', 'host_identity_verified']\n",
        "listings_df1.dropna(subset=cols_na, inplace=True)"
      ],
      "id": "9cc19f69",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#print(f\"Data frame is now {listings_df1.shape[0]:,} x {listings_df1.shape[1]}\") # Prints: Data frame is now 87,941 x 30"
      ],
      "id": "098b295c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Just check again \n",
        "#listings_df1.isnull().sum(axis=0).sort_values(ascending=False)"
      ],
      "id": "9ebfdb52",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Price analysis\n"
      ],
      "id": "0061a4ca"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### 6.1.1 Data standardization_Price\n",
        "money = ['price']\n",
        "#listings_df1.sample(5, random_state=42)[money] # Just check"
      ],
      "id": "f5198f67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# The 'price' column has a dollar sign and comma, need to drop comma and dollar sign  \n",
        "for m in money:\n",
        "    #print(f\"Converting {m}\")\n",
        "    listings_df1[m] = listings_df1[m].str.replace('$','', regex=False).str.replace(',','', regex=False).astype('float')"
      ],
      "id": "360e750b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check it worked \n",
        "#listings_df1.sample(5, random_state=42)[money]"
      ],
      "id": "f7984d00",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check for extremes \n",
        "#listings_df1[listings_df1['price'] == 0]"
      ],
      "id": "7db9d439",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#delete the ones where price is 0 \n",
        "listings_df1=listings_df1[listings_df1['price'] != 0]"
      ],
      "id": "c0ec9390",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Just check agian\n",
        "#print(f\"Data frame is now {listings_df1.shape[0]:,} x {listings_df1.shape[1]}\") # Prints: Data frame is now 87,938 x 30"
      ],
      "id": "b363ee32",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# There are also some columns that should be numeric. Converting columns into integers.  \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ints = [\n",
        "    'id', 'host_id', 'host_listings_count', 'host_total_listings_count',\n",
        "    'minimum_nights', 'maximum_nights', 'minimum_minimum_nights',\n",
        "    'maximum_minimum_nights'\n",
        "]\n",
        "\n",
        "for i in ints:\n",
        "    #print(f\"Converting {i}\")\n",
        "    try:\n",
        "        # Fill NaN values with a placeholder and convert to integers.\n",
        "        listings_df1[i] = listings_df1[i].astype('float').fillna(-1).astype('int')\n",
        "    except ValueError as e:\n",
        "        print(\"  - Error converting to integer, filling NaN with placeholder and converting to unsigned 16-bit integer.\")\n",
        "        # Correct the variable name to listings_df1\n",
        "        listings_df1[i] = listings_df1[i].astype('float').fillna(0).astype(pd.UInt16Dtype())\n",
        "\n",
        "# Replace the placeholder with NaN if needed\n",
        "for i in ints:\n",
        "    listings_df1[i] = listings_df1[i].replace(-1, pd.NA)"
      ],
      "id": "3f332ed2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# room_type, make boolean\n",
        "# property_type, make boolean\n",
        "listings_df1.room_type.astype('category').memory_usage(deep=True) \n",
        "pass"
      ],
      "id": "7bc6a689",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "listings_df1.property_type.astype('category').memory_usage(deep=True)\n",
        "pass"
      ],
      "id": "45cd23be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data set shows discrepancies related to prices with numerous listings having unrealistically high prices. To avoid a skewed result towards higher prices, we excluded prices over 1500 GBP for the analyisis. A more thorough analysis of higher end price listing, e.g. by assessing the reviews, would allow to increase the accuracy of results but is beyond the scope of this project.\n",
        "\n",
        "The histogram in figure 1 displays the price distribution, revealing a positive skew towards lower prices with a sparse tail of higher-priced listings. The accompanying box plot in figure 2 provides key descriptive statistics, including the median listing price at 106.00, with 50% of the data falling within the range of 65.00 to 176.00. \n"
      ],
      "id": "c780bd52"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### desriptive statistics ####\n",
        "\n",
        "# The mean and median price of airbnb in London is. \n",
        "#print(f\"The mean price is ${listings_df1.price.mean():0.2f}\") # Prints: The mean price is $181.36\n",
        "#print(f\"The median price is ${listings_df1.price.median():0.2f}\") # Prints: The median price is $110.00\n",
        "#print(f\"The min price is ${listings_df1.price.min():0.2f}\") # Prints: The min price is $1.00\n",
        "#print(f\"The max price is ${listings_df1.price.max():0.2f}\") # Prints: The max price is $80100.00\n",
        "#print(f\"The price standard deviattion is ${listings_df1.price.std():0.2f}\") # Prints: The price standard deviattion is $486.19"
      ],
      "id": "fedf2b60",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#listings_df1[listings_df1['price']==80100]['listing_url']"
      ],
      "id": "41fc248a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# convert the column 'price'\n",
        "ints_price  = ['price']\n",
        "for i in ints_price:\n",
        "    #print(f\"Converting {i}\")\n",
        "    try:\n",
        "        listings_df1[i] = listings_df1[i].astype('float').astype('int')\n",
        "    except ValueError as e:\n",
        "        print(\"  - !!!Converting to unsigned 16-bit integer!!!\")\n",
        "        df[i] = listings_df1[i].astype('float').astype(pd.UInt16Dtype())"
      ],
      "id": "b7eab416",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Filter too large 'price' number\n",
        "# set '2000' as special number, check and show the rows which 'price' is larger than '2000'\n",
        "count_gt_2000 = len(listings_df1[listings_df1['price'] > 2000])\n",
        "rows_gt_2000 = listings_df1[listings_df1['price'] > 2000]\n",
        "#print(f\"The number of row which 'price' is larger than '2000'：{count_gt_2000} rows\")\n",
        "\n",
        "#price_review = rows_gt_2000[rows_gt_2000['number_of_reviews_ltm']>0]\n",
        "#print(price_review[['price', 'number_of_reviews_ltm', 'property_type', 'room_type']])"
      ],
      "id": "1c83e71c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#listings_df1.iloc[4962]['listing_url']"
      ],
      "id": "e1d6043b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "listings_df1.drop(listings_df1[listings_df1['price'] >= 1500].index, inplace=True)\n",
        "#listings_df1.shape"
      ],
      "id": "392dade4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Plot.histogram ###\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Plot histogram with prices less than 1500\n",
        "plt.figure(figsize=(10, 6))\n",
        "price_histogram = listings_df1[listings_df1['price'] < 1500]['price'].plot.hist(bins=200)\n",
        "plt.xlabel('Price')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Prices Below 1500')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "b69dda77",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Figure 1 - Historgram Price**\n"
      ],
      "id": "942c7f18"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Box plot ###\n",
        "\n",
        "# calculate the price between 5%-95%\n",
        "percentile_05 = listings_df1['price'].quantile(0.05)\n",
        "percentile_95 = listings_df1['price'].quantile(0.95)\n",
        "data = listings_df1[(listings_df1['price'] >= percentile_05) & (listings_df1['price'] <= percentile_95)]['price']\n",
        "\n",
        "# create a new figure\n",
        "plt.figure(figsize=(5, 8))\n",
        "\n",
        "# create a box plot()\n",
        "plt.boxplot(data, vert=True) \n",
        "\n",
        "# Create the x-coordinate of the data points (arranged along the ordinate)\n",
        "#x_coordinates = np.ones(len(data))\n",
        "x_coordinates = np.random.normal(1, 0.04, size=len(data))  # Add slight perturbation to avoid overlap\n",
        "\n",
        "# add points\n",
        "plt.scatter(x_coordinates, data, color='red', marker='o', s=0.5, label='Data Points', alpha = 0.2)\n",
        "\n",
        "# Set the style of outliers\n",
        "flierprops = dict(marker='o', markerfacecolor='blue', markersize=5, linestyle='none', markeredgecolor='black')\n",
        "whiskerprops = {'linewidth':0.5}\n",
        "plt.boxplot(data, vert=True, whiskerprops=whiskerprops, flierprops=flierprops)\n",
        "\n",
        "# Set X-axis tick labels\n",
        "plt.xticks([1], ['Data'])\n",
        "\n",
        "# Show legend\n",
        "plt.legend()\n",
        "\n",
        "# Label values for minimum, first quartile, median, third quartile, and maximum\n",
        "plt.text(0.75, min(data), f'Minimum: {min(data):.2f}', va='bottom', ha='center')\n",
        "plt.text(0.75, np.percentile(data, 25), f'1st Quartile: {np.percentile(data, 25):.2f}', va='bottom', ha='center')\n",
        "plt.text(0.75, np.median(data), f'Median: {np.median(data):.2f}', va='bottom', ha='center')\n",
        "plt.text(0.75, np.percentile(data, 75), f'3rd Quartile: {np.percentile(data, 75):.2f}', va='bottom', ha='center')\n",
        "plt.text(0.75, max(data), f'Maximum: {max(data):.2f}', va='bottom', ha='center')\n",
        "\n",
        "# show plot\n",
        "plt.show()"
      ],
      "id": "a395704b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Figure 2 - Box Plot Price**\n"
      ],
      "id": "9b801932"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Plot.scatter of price distribution ###\n",
        "\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pysal as p\n",
        "import mapclassify as mc\n",
        "import palettable.matplotlib as palmpl\n",
        "from legendgram import legendgram\n",
        "\n",
        "# define price_range\n",
        "price_ranges = [(0,50), (50,100), (100,150), (150,200), (200,250), (250,300), (300,float('inf'))]\n",
        "\n",
        "# create a new column 'price_range', reflect prices by 'price_range' to the corresponding labels \n",
        "listings_df1['price_range'] = pd.cut(listings_df1['price'], \n",
        "                                       bins=[0, 50, 100, 150, 200, 250, 300, float('inf')],\n",
        "                                       labels=['(0, 50)', '(50, 100)', '(100, 150)', '(150, 200)', '(200, 250)', '(250, 300)', '300+'],\n",
        "                                       right=False)\n",
        "\n",
        "# If your gdf is not in WGS 84 (latitude/longitude), and your listings_df1 data is in WGS 84, you need to convert it.\n",
        "# Ensure listings data is in a GeoDataFrame with the correct CRS.\n",
        "gdf_listings = gpd.GeoDataFrame(\n",
        "    listings_df1,\n",
        "    geometry=gpd.points_from_xy(listings_df1.longitude, listings_df1.latitude),\n",
        "    crs=\"EPSG:4326\"  # WGS 84\n",
        ")\n",
        "# Now convert the listings GeoDataFrame to match the CRS of the borough boundaries GeoDataFrame.\n",
        "gdf_listings = gdf_listings.to_crs(gdf.crs)\n",
        "\n",
        "# Now we can plot both on the same Axes object.\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
        "# Set the color of the boroughs.\n",
        "gdf.plot(ax=ax, color='none', edgecolor='black', facecolor='black', linewidth=1.5)  \n",
        "gdf_listings.plot(ax=ax, column='price_range', cmap='RdBu_r', legend=True, \n",
        "                 marker='.', markersize=3, zorder=4)\n",
        "\n",
        "# Set axis labels and title using a specified font, weight, and size\n",
        "ax.set_xlabel('Easting', fontsize=15)\n",
        "ax.set_ylabel('Northing', fontsize=15)\n",
        "ax.set_title('Airbnb Listing Price Distribution in London Borough', \n",
        "             fontdict={'fontsize':'20', 'fontweight':'3'})  #provide a title\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "#listings_df1.drop(columns=['price_range'], inplace=True)"
      ],
      "id": "88b649f3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Figure 3 - Scatter plot price**\n",
        "\n",
        "The spatial distribution map in figure 3 shows that there are higer number of listings with higher prices in inner city London. \n",
        "\n",
        "### 6.2 \"Host type\" analysis\n",
        "\n",
        "\"Host type\" refers to whether the host has one or multiple listings. We assume that those with multiple listings are commercial hosts, which is in contrast to the intended peer to peer character of Airbnb. \n"
      ],
      "id": "8f0b79d7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Percentage of individual hosts (local hosts) in the total number of hosts ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Updated function to calculate the ratio of single listings by neighbourhood\n",
        "def calculate_host_type(group):\n",
        "    # Calculate the count of single listings\n",
        "    single_listings_count = (group['calculated_host_listings_count'] == 1).sum()\n",
        "    # Calculate the ratio of single listings\n",
        "    local_host_proportion = single_listings_count / len(group)\n",
        "    # Return the ratio with the neighbourhood name\n",
        "    return pd.Series({'local_host_proportion': local_host_proportion})\n",
        "\n",
        "# Group by neighbourhood and apply the calculation, then reset index\n",
        "local_host_proportion_df = listings_df1.groupby('neighbourhood_cleansed').apply(calculate_host_type).reset_index()\n",
        "\n",
        "# Display the resulting DataFrame\n",
        "#local_host_proportion_df"
      ],
      "id": "1682649c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "\n",
        "# Merge your data with the GeoDataFrame\n",
        "# Make sure the left and right column names are correct\n",
        "local_host_proportion_df_gdf = gdf.merge(local_host_proportion_df, left_on='NAME', right_on='neighbourhood_cleansed')\n",
        "\n",
        "# Plot the map\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "local_host_proportion_df_gdf.plot(column='local_host_proportion', ax=ax, legend=True, cmap='RdBu_r', edgecolor='white', \n",
        "                   legend_kwds={'label': \"Proportion of local host\",\n",
        "                                'orientation': \"vertical\",\n",
        "                                'shrink': 0.7})\n",
        "\n",
        "# Set axis labels and title using a specified font, weight, and size\n",
        "ax.set_xlabel('Easting', fontsize=15)\n",
        "ax.set_ylabel('Northing', fontsize=15)\n",
        "ax.set_title('Proportion of local host in London Borough', \n",
        "             fontdict={'fontsize':'20', 'fontweight':'3'})  #provide a title\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "9022f942",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Figure 4 - Local hosts**\n",
        "\n",
        "Figure 3 shows that there are more single hosts in outer London boroughs than inner London boroughs, such as Camden, Westminster, city of London and Kensington and Chelsea. \n",
        "\n",
        "## 6.3 \"Occupancy\" analysis\n",
        "\n",
        "Occupancy of a listing is the number of nights an Airbnb was booked per year. The occupancy rate is calculated as a function of the number if reviews in the last 12 months (assuming a 50% review rate) and the minimun number of nights requried to book following the San Fransico Model from Inside Airbnb analysis. [@insideairbnb]\n"
      ],
      "id": "f8450205"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# calculate the occupancy day in 2023 year\n",
        "def calculate_occupancy(df):\n",
        "    df['occupancy_rate'] = df['number_of_reviews_ltm'] / 12 * 3 / 0.50\n",
        "    df['occupancy'] = df['occupancy_rate'] * df['minimum_nights']\n",
        "    return df['occupancy'].sum()\n",
        "\n",
        "# use groupby() divide into boroughs and apply calculate_occupancy() function\n",
        "occupancy_by_borough = listings_df1.groupby('neighbourhood_cleansed').apply(calculate_occupancy)\n",
        "\n",
        "# Convert the result to a DataFrame with the correct column name.\n",
        "occupancy_by_borough_df = occupancy_by_borough.reset_index(name='occupancy')\n",
        "\n",
        "#print(type(occupancy_by_borough_df))\n",
        "#occupancy_by_borough_df"
      ],
      "id": "28ff6c5e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataframe 'neighborhood_counts' ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# use groupby() & size() to calculate rows number which is realted to each variables\n",
        "neighborhood_counts = listings_df1.groupby('neighbourhood_cleansed').size().reset_index(name='total_listings')\n",
        "\n",
        "# print(type(neighborhood_counts)) # Prints:<class 'pandas.core.frame.DataFrame'>\n",
        "# neighborhood_counts"
      ],
      "id": "e88bf5f9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Merging the dataframes on 'neighbourhood_cleansed'\n",
        "merged_occupancy_df = occupancy_by_borough_df.merge(neighborhood_counts, on='neighbourhood_cleansed')\n",
        "merged_occupancy_df['avarage_occupancy_day'] = merged_occupancy_df['occupancy'] / merged_occupancy_df['total_listings']\n",
        "\n",
        "#merged_occupancy_df"
      ],
      "id": "d336f3e9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Make a Map\n",
        "\n",
        "# Merge your data with the GeoDataFrame\n",
        "merged_occupancy_gdf = gdf.merge(merged_occupancy_df, left_on='NAME', right_on='neighbourhood_cleansed')\n",
        "\n",
        "# Plot the map\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
        "merged_occupancy_gdf.plot(column='avarage_occupancy_day', ax=ax, legend=True, cmap='RdBu_r', edgecolor='white',\n",
        "                legend_kwds={'label': \"Avarage Occupancy Day\",\n",
        "                             'orientation': \"vertical\", \n",
        "                             'shrink': 0.7})\n",
        "\n",
        "# Set axis labels and title using a specified font, weight, and size\n",
        "ax.set_xlabel('Easting', fontsize=15)\n",
        "ax.set_ylabel('Northing', fontsize=15)\n",
        "ax.set_title('Avarage Occupancy Day in London Borough', \n",
        "             fontdict={'fontsize':'20', 'fontweight':'3'})  #provide a title\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "id": "62422c1d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Figure 5 - Occupancy rate {style=\"text-align:center; font-weight:bold; font-size:largest\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The occupancy map in figure 4 reveals that central London boroughs have higher occupancies than outer London borough, especially in touristy areas such as Westminster or Camden. The highest occupancy rates are seen in Kingston upon Themes. To understand this result fully, further analysis, e.g. assessing local tourist attraction and major events, would be needed.\n",
        "\n",
        "\n",
        "\n",
        "## 7. Drawing on your previous answers, and supporting your response with evidence, how could this data set be used to inform the regulation of STL in London?\n",
        "\n",
        "## 7.1 Regulation of short-term lets\n",
        "\n",
        "Short-Term lets’ rising popularity has raised many concerns about traditional lodging industries and neighbourhood housing markets. The 90-day rule is brought up in 2015 in response to this worry to restrict the total full occupancy period of STL properties to 90 days per year. [@Shabrina:2019] \n",
        "\n",
        "## 7.2 Research\n",
        "\n",
        "### 7.2.1 Research Question\n",
        "\n",
        "Airbnb claims that it contributes to dispersing tourism across the London boroughs, as well as returns to the local communities with up to 97% what they charge and revitalisation of local tourism economies. [@Airbnb2019]\n",
        "\n",
        "Our research question is: Do Airbnb's listings contribute to local tourism economy equally in inner and outer London boroughs?\n",
        "\n",
        "### 7.2.2 Approach\n",
        "\n",
        "1. To assess tourist expenditure that benefits the local community (local economic contribution), we assume that it comes from \"money paid to the local host\" and \"money spent in local business\"\n",
        "\n",
        "**income of local host =  price * occupancy rate * number of nights**\n",
        "\n",
        "**tourist local spending =  occupancy rate * number of nights * number of people * daily consumption**\n",
        "\n",
        "\"daily consumption\": Based on the GLA's Tourism Forcasts [@touristforecast2022], the average visitor spending per day in London is 120 GBP in 2022. As subtracting accommodation, trasnport and tourist spending, we assume \"daily local consumption\" will be around 30 GBP or 25% of the total daily spending, which includes breakfast, some dinner and grocery shopping.\n",
        "\n",
        "2. Calculating the economic contribution per listing in each London Borough\n",
        "\n",
        "**Money of local economic contribution per listing = sum of money / number of listings per borough**\n",
        "\n",
        "3. Producing a map of London that allows comparison between the boroughs.\n",
        "\n",
        "### 7.2.3 Equation and Process\n",
        "\n",
        "**1. Money to the local economy for each listing = tourist local spending + income of local host**\n",
        "\n",
        "**2. Income of single host =  price * occupancy rate * number of nights for singel host's listings**\n",
        "\n",
        "*(1) occupancy rate = review/(50%) based on 'San Francisco Model'*\n",
        "\n",
        "*(2) number of nights (per booking): use \"minimum_nights\"*\n"
      ],
      "id": "be74d0ea"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "pd.options.mode.chained_assignment=None # default='warn'"
      ],
      "id": "d626ec51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "listings_df1_localhost = listings_df1[listings_df1['calculated_host_listings_count'] == 1]"
      ],
      "id": "f0b755b3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#listings_df1.shape"
      ],
      "id": "f2d00a34",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#listings_df1_localhost.shape\n",
        "# This means almost half of host have multiple listings, \n",
        "# which means half of hosts won't have economic contribution to this community/borough.\n",
        "# This result is similar with the outcome from **Inside Airbnb**. \n",
        "# It shows **43,382 (49.3%) single listings** and **44,565 (50.7%) multi-listings"
      ],
      "id": "cbf0dc07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Price ###\n",
        "\n",
        "#Just check\n",
        "#listings_df1_localhost.sample(5, random_state=42)[money]"
      ],
      "id": "9872b39c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check 'NA'\n",
        "#listings_df1_localhost[listings_df1_localhost.listing_url.isna()][['id','listing_url','name','description','host_id','host_name','price']]\n",
        "# No 'NA'"
      ],
      "id": "ad98883b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Just check again \n",
        "#listings_df1_localhost.isnull().sum(axis=0).sort_values(ascending=False)[:20]"
      ],
      "id": "bacda145",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# NAN of rows\n",
        "#listings_df1_localhost.isnull().sum(axis=1).sort_values(ascending=False).head(10)"
      ],
      "id": "ad5bb221",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### occupancy rate ###\n",
        "\n",
        "listings_df1_localhost.loc[:, 'occupancy_rate'] = listings_df1_localhost['number_of_reviews_ltm'] / 12 * 3 / 0.50\n",
        "#print(listings_df1_localhost['occupancy_rate'])\n",
        "\n",
        "#print(listings_df1_localhost[['occupancy_rate']].sort_values(by='occupancy_rate', ascending=False)) # Prints: [43380 rows x 1 columns]\n",
        "\n",
        "# print(listings_df1_localhost[listings_df1['occupancy_rate'] == 0])\n",
        "#listings_df1_localhost[listings_df1_localhost['occupancy_rate'] == 0].shape # Prints: (25607, 36) \n",
        "\n",
        "# Which means (actually the whole 2023 year) almost half of listings don't be used\n",
        "\n",
        "# There are 43380 listings in dataframe. However, there are 256078 rows which value of 'occupancy_rate' is 0.0. Which means these listings didn't get any review in 2023 year. \n",
        "# Based on San F Model, it means almost half of listings don't be used in 2023 year."
      ],
      "id": "0b5cee8e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# create a new column \"host_income\"\n",
        "listings_df1_localhost.loc[:, 'host_income'] = (\n",
        "    listings_df1_localhost['price'] *\n",
        "    listings_df1_localhost['occupancy_rate'] *\n",
        "    listings_df1_localhost['minimum_nights']\n",
        ")\n",
        "\n",
        "# Sum it up to calculate total income\n",
        "host_income_quarter = listings_df1_localhost['host_income'].sum()\n",
        "\n",
        "# Print the result with formatted string\n",
        "#print(f\"The host income for the quarter: ${host_income_quarter:.2f}\")"
      ],
      "id": "835fa6d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**3. Tourist local spending =  occupancy rate * number of nights * number of people * 30GBP**\n",
        "\n",
        "*(1) 'occupancy rate' and 'number of nights': When we use Equation1, we filter the hosts who have multiple listings. However, tourists contribute to the local economy whether they are staying in the listings which belong to local host or a non-local host. So we use listings_df1.*\n",
        "\n",
        "*(2) number of nights (per booking): We use column 'minimum_nights'*\n",
        "\n",
        "*(3) number of people: It means number of tourist per listing. We consider 'accommodates' is equal to accommodates.*\n",
        "\n",
        "*(4) We use 30 GBP temporarily.*\n",
        "\n",
        "*(5) Calculate 'tourist local spending'*\n",
        "\n",
        "(We need some literatures to support 30 GBP)\n"
      ],
      "id": "7a1d6e24"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### \"occupancy_rate\" in listings_df1 ###\n",
        "\n",
        "listings_df1['occupancy_rate'] = listings_df1['number_of_reviews_ltm'] / 12 * 3 / 0.50\n",
        "#print(listings_df1['occupancy_rate'])\n",
        "\n",
        "#print(listings_df1[['occupancy_rate']].sort_values(by='occupancy_rate', ascending=False)) # Prints: [87941 rows x 1 columns]\n",
        "\n",
        "# print(listings_df1[listings_df1['occupancy_rate'] == 0])\n",
        "#listings_df1[listings_df1['occupancy_rate'] == 0].shape \n",
        "# Prints: (43248, 36) \n",
        "# Which means (actually the whole 2023 year) almost half of listings don't be used"
      ],
      "id": "5265742e",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Calculate \"tourist local spending\" ###\n",
        "\n",
        "# create a new column \"tourist local spending\"\n",
        "listings_df1['tourist_local_spending'] = listings_df1['occupancy_rate'] * listings_df1['minimum_nights'] * listings_df1['accommodates'] * 30\n",
        "\n",
        "# sum it up\n",
        "tourist_local_spending_quarter = listings_df1['tourist_local_spending'].sum()\n",
        "\n",
        "#print(f\"The host income for the quarter: ${tourist_local_spending_quarter:.2f}\")"
      ],
      "id": "cbb7b75c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**4. Group by boroughs and calculate economic eontribution in each London borough per listing**\n"
      ],
      "id": "cab43a18"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataframe 'income_by_borough_df' ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# define function calculate_host_income\n",
        "def calculate_host_income(df):\n",
        "    df['occupancy_rate'] = df['number_of_reviews_ltm'] / 12 * 3 / 0.50\n",
        "    df['host_income'] = df['price'] * df['occupancy_rate'] * df['minimum_nights']\n",
        "    return df['host_income'].sum()\n",
        "\n",
        "# group by boroughs\n",
        "income_by_borough = listings_df1_localhost.groupby('neighbourhood_cleansed').apply(calculate_host_income)\n",
        "\n",
        "# Convert the result to a DataFrame with the correct column name.\n",
        "income_by_borough_df = income_by_borough.reset_index(name='income_by_borough')\n",
        "\n",
        "# print(type(income_by_borough_df)) # Prints: <class 'pandas.core.frame.DataFrame'>\n",
        "# income_by_borough_df"
      ],
      "id": "c909b54c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataframe 'spending_by_borough_df' ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# define function tourist_local_spending\n",
        "def calculate_tourist_local_spending(df):\n",
        "    df['occupancy_rate'] = df['number_of_reviews_ltm'] / 12 * 3 / 0.50\n",
        "    df['tourist_local_spending'] = df['occupancy_rate'] * df['minimum_nights'] * df['accommodates'] * 30\n",
        "    return df['tourist_local_spending'].sum()\n",
        "\n",
        "# group by boroughs\n",
        "spending_by_borough = listings_df1.groupby('neighbourhood_cleansed').apply(calculate_tourist_local_spending)\n",
        "\n",
        "# Convert the result to a DataFrame with the correct column name.\n",
        "spending_by_borough_df = spending_by_borough.reset_index(name='spending_by_borough')\n",
        "\n",
        "# print(type(spending_by_borough_df)) # Prints: <class 'pandas.core.frame.DataFrame'>\n",
        "# spending_by_borough_df"
      ],
      "id": "86b26540",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Dataframe 'neighborhood_counts' ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# use groupby() & size() to calculate rows number which is realted to each variables\n",
        "neighborhood_counts = listings_df1.groupby('neighbourhood_cleansed').size().reset_index(name='total_listings')\n",
        "\n",
        "# print(type(neighborhood_counts)) # Prints:<class 'pandas.core.frame.DataFrame'>\n",
        "# neighborhood_counts"
      ],
      "id": "c080c526",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Merge these Dataframes all together ###\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Merging the dataframes on 'neighbourhood_cleansed'\n",
        "merged_df = income_by_borough_df.merge(spending_by_borough_df, on='neighbourhood_cleansed')\n",
        "merged_df = merged_df.merge(neighborhood_counts, on='neighbourhood_cleansed')\n",
        "merged_df['contribution_per_listing'] = (merged_df['income_by_borough'] + merged_df['spending_by_borough']) / merged_df['total_listings']\n",
        "\n",
        "#merged_df"
      ],
      "id": "c2a2a31a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Draw the map ###\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import geopandas as gpd\n",
        "\n",
        "# Assuming 'gdf' is your GeoDataFrame with the London borough boundaries\n",
        "# and 'merged_df' is your DataFrame with the 'ratio' column.\n",
        "\n",
        "# Merging the GeoDataFrame with your data\n",
        "merged_gdf = gdf.merge(merged_df, left_on='NAME', right_on='neighbourhood_cleansed')\n",
        "\n",
        "# Creating the plot\n",
        "fig, ax = plt.subplots(1, 1, figsize=(15, 15))\n",
        "merged_gdf.plot(column='contribution_per_listing', ax=ax, legend=True, cmap='RdBu_r', edgecolor='white',\n",
        "                legend_kwds={'label': \"Contribution by Borough\",\n",
        "                             'orientation': \"vertical\", \n",
        "                             'shrink': 0.7})\n",
        "\n",
        "# Adding the borough names to the plot\n",
        "for idx, row in merged_gdf.iterrows():\n",
        "    plt.annotate(text=row['NAME'], xy=(row['geometry'].centroid.x, row['geometry'].centroid.y), ha='center', fontsize=8)\n",
        "\n",
        "# Adding a title to the plot\n",
        "plt.title('Local Economic Contribution in London Boroughs (per listing)', fontsize=20)\n",
        "\n",
        "# Removing the axes for a cleaner look\n",
        "ax.set_axis_off()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "id": "3ee5aefd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Figure 5**\n"
      ],
      "id": "c7546fe7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "### Draw a histogram ###\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Sorting the DataFrame by ratio in descending order for better visual representation\n",
        "merged_sorted_df = merged_df.sort_values('contribution_per_listing', ascending=True)\n",
        "\n",
        "# Set a color board\n",
        "cmap = plt.get_cmap('RdBu_r')\n",
        "norm = mcolors.Normalize(vmin=merged_sorted_df['contribution_per_listing'].min(), vmax=merged_sorted_df['contribution_per_listing'].max())\n",
        "colors = cmap(norm(merged_sorted_df['contribution_per_listing']))\n",
        "\n",
        "# Plotting the bar chart\n",
        "fig, ax = plt.subplots(figsize=(10, 8))  # create a fig object and an ax object\n",
        "ax.barh(merged_sorted_df['neighbourhood_cleansed'], merged_sorted_df['contribution_per_listing'], color=colors)\n",
        "ax.set_xlabel('Contribution per Listing', fontsize=12)\n",
        "ax.set_ylabel('Neighbourhood', fontsize=12)\n",
        "ax.set_title('Economic Contribution in London Boroughs (per listing)', fontsize=20)\n",
        "\n",
        "# Create a colorbar\n",
        "sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
        "sm.set_array([])  # Just to show the colorbar\n",
        "cbar = plt.colorbar(sm, ax=ax)  # define prarmeter of ax\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "a52c0d16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Figure 6 - Average contribution to bouroughs local tourist economy per listing** \n",
        "\n",
        "### 7.2.4 Result: Average Local Economic Contribution Per Listing Per Borough\n",
        "According to Figure 5 and 6, the listings have larger average return to the local economy in inner London boroughs than outer London boroughs. The top contributor belongs to listings in Camden, Kensington and Chelsea and Richmond Upon Thames. From the equation, two independent variables are identified that lead to this result: a high occupancy and b, high price per night. This also correlates to previous results in Figure 3 and 4, where the occupancy and price per listing per night follows the same trend. \n",
        "\n",
        "## 7.3 regulation implications\n",
        "\n",
        "### 7.3.1 Impose central London restrictions on multi-hosts and promote single-hosts to harness and maximise the local economic impact. \n",
        "This promotion can involve incentives for hosts with only one property or a shared flat, alongside varying levels of taxation based on the number of listings for multi-hosts. Rebalancing the ratio of single and multi-hosts, especially in areas with high occupancy and prices, can rapidly boost the local economy while also preserving a authentic character of the location. \n",
        " \n",
        "### 7.3.2 Incentivise outer London STL to develop higher occupancy and number of listings. \n",
        "This could be achieved by incentivising Airbnb to propose discounted lets for single-hosts. The positive correlation of occupancy and local contribution from figure 4 and 5 indicates that enhancing occupancy can positively influence the tourism economy of non-central area, aligning with Airbnb’s asserted values.  \n",
        " \n",
        "### 7.3.3 Enhance monitoring and ensure data accuracy to enforce the 90-night limit. \n",
        "@Nieuwland2018 highlighted London's lenient approach to Airbnb, leading to a surge in violations of regulations, notably surpassing the allowed Short-Term Let (STL) period of 90 days. Recent research conducted by the Greater London Authority (GLA) in Camden has uncovered a significantly higher magnitude of such activities compared to data available on Inside Airbnb. [@GLA2023] Their research showed that 50% of the listings in the five Inner London boroughs exceeded the 90-night limit. This stands in contrast to the seemingly low average of 10-11 days per listing portrayed in Figure 4 for these identified hotspots. \n",
        "\n",
        "### 7.3.4 License STL hosts to improve compliance with regulation. \n",
        "@Nieuwland2018 demonstrates the city of Denver benefits  from balancing externalities of STLs in three ways Firstly, it facilitates easier identification of violations by monitoring and regulating Airbnb concerning maximum days, listing and host types. Secondly, licensing system fosters hosts’ responsibility because it treats them as proper businesses rather than just platform users. Lastly, it leads to higher compliance rate. Denver’s number of STL listings dropped by 14.5% after enforcement of licenses in 2017  as unlawful listings were screened out. [@Arello2017] \n",
        "\n",
        "## 7.4 Limitations\n",
        "Due to the limited scope of the study, the data cleaning approach as well as the model have some weaknesses including:\n",
        "Method limitation: STL business was identified by whether it’s multi- or single host. this preliminary estimation is not accurate because listing numbers may vary for Airbnb business. Better estimation can be done using cluster analysis.\n",
        "Model limitation: 100% of the single host income is considered in the local economy contribution, which is likely an overestimation. \n",
        "Data limitation: It is evidenced in the GLA report and others that the data Airbnb provided is far from accurate. Therefore, it worths taking into consideration that the data we used from Inside Airbnb scrapping is also biased.\n",
        "\n",
        "## Sustainable Authorship Tools\n",
        "\n",
        "Your QMD file should automatically download your BibTeX file. We will then re-run the QMD file to generate the output successfully.\n",
        "\n",
        "Written in Markdown and generated from [Quarto](https://quarto.org/). Fonts used: [Spectral](https://fonts.google.com/specimen/Spectral) (mainfont), [Roboto](https://fonts.google.com/specimen/Roboto) (<span style=\"font-family:Sans-Serif;\">sansfont</span>) and [JetBrains Mono](https://fonts.google.com/specimen/JetBrains%20Mono) (`monofont`). \n",
        "\n",
        "## References"
      ],
      "id": "912b12e5"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "jupytext": {
      "text_representation": {
        "extension": ".qmd",
        "format_name": "quarto",
        "format_version": "1.0",
        "jupytext_version": "1.15.2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}